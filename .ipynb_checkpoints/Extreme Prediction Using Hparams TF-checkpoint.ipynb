{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "HP_NUM_UNITS1 = hp.HParam('num_units 1', hp.Discrete([4,8,16])) \n",
    "HP_NUM_UNITS2 = hp.HParam('num_units 2', hp.Discrete([4,8]))\n",
    "#HP_DROPOUT = hp.HParam('dropout', hp.RealInterval(0.1, 0.3))\n",
    "HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam', 'sgd','RMSprop']))\n",
    "HP_L2 = hp.HParam('l2 regularizer', hp.RealInterval(.001,.01))\n",
    "METRIC_RMSE = 'RootMeanSquaredError'\n",
    "\n",
    "n = 20\n",
    "# Set forecasting window length (in years)\n",
    "m = 4\n",
    "# Set annual sampling rate\n",
    "f = 12 \n",
    "\n",
    "freq = 12\n",
    "h = m*f\n",
    "n_steps = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequence(sequence, n_steps):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps\n",
    "        # check if we are beyond the sequence\n",
    "        if end_ix > len(sequence)-1:\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "\n",
    "def train_test_split_ts_2d_raw(X, h):\n",
    "    return(X[:-h],X[-h:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../extreme_data/raw12_3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.iloc[1:,1].values\n",
    "oni = data.iloc[1:,2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_list = []\n",
    "for index in range(0,int((L - (n+m)*f)/12)):\n",
    "    raw_seq = x[index:index+(n+m)*f]\n",
    "    X, y = split_sequence(raw_seq, n_steps)\n",
    "\n",
    "    #oni_seq = oni[index:index+(n+m)*f]\n",
    "    #X_oni, _ = split_sequence(oni_seq, n_steps)\n",
    "\n",
    "    #X = np.hstack((X_oni,X))\n",
    "\n",
    "    #X_norm = (X - X.mean(0))/X.std(0)\n",
    "\n",
    "    x_train, x_test = train_test_split_ts_2d_raw(X, h)\n",
    "    y_train, y_test = train_test_split_ts_2d_raw(y, h)\n",
    "\n",
    "    def train_test_model(hparams):\n",
    "        model = tf.keras.Sequential([\n",
    "            tf.keras.layers.InputLayer(input_shape = x_train.shape[1]),\n",
    "            layers.Dense(hparams[HP_NUM_UNITS1], kernel_regularizer=tf.keras.regularizers.l2(0.001), activation=tf.nn.relu),\n",
    "            layers.Dropout(0.1),\n",
    "            layers.Dense(hparams[HP_NUM_UNITS2], kernel_regularizer=tf.keras.regularizers.l2(0.001), activation=tf.nn.relu),\n",
    "            layers.Dense(1)\n",
    "        ])\n",
    "\n",
    "        model.compile(optimizer=hparams[HP_OPTIMIZER],\n",
    "                    loss='mean_squared_error',\n",
    "                    metrics=['RootMeanSquaredError'])\n",
    "\n",
    "        model.fit(x_train, y_train, epochs=100,verbose=False) \n",
    "        _, rmse = model.evaluate(x_test, y_test, verbose=False)\n",
    "        return rmse\n",
    "\n",
    "    def run( hparams):\n",
    "        #with tf.summary.create_file_writer(run_dir).as_default():\n",
    "        hp.hparams(hparams)  # record the values used in this trial\n",
    "        rmse = train_test_model(hparams)\n",
    "        #    tf.summary.scalar(METRIC_RMSE, rmse, step=1)\n",
    "        return(rmse, hparams)\n",
    "\n",
    "    session_num = 0\n",
    "    min_rmse = float('inf')\n",
    "    best_hparams = {}\n",
    "    for num_units1 in HP_NUM_UNITS1.domain.values:\n",
    "        for num_units2 in HP_NUM_UNITS2.domain.values:\n",
    "            #for dropout_rate in (HP_DROPOUT.domain.min_value, HP_DROPOUT.domain.max_value):\n",
    "            for l2 in (HP_L2.domain.min_value, HP_L2.domain.max_value):\n",
    "                for optimizer in HP_OPTIMIZER.domain.values:\n",
    "                    hparams = {\n",
    "                        HP_NUM_UNITS1: num_units1,\n",
    "                        HP_NUM_UNITS2: num_units2,\n",
    "                        #HP_DROPOUT: dropout_rate,\n",
    "                        HP_L2: l2,\n",
    "                        HP_OPTIMIZER: optimizer\n",
    "                    }\n",
    "                    run_name = \"run-%d\" % session_num\n",
    "                    #print('--- Starting trial: %s' % run_name)\n",
    "                    #print({h.name: hparams[h] for h in hparams})\n",
    "                    rmse, current_hparams = run(hparams)\n",
    "                    if ~np.isnan(rmse) and rmse < min_rmse: \n",
    "                        best_hparams = current_hparams\n",
    "                        min_rmse = rmse\n",
    "                    session_num += 1\n",
    "\n",
    "    params = list(best_hparams.values())\n",
    "    rmse_list.append(min_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{HParam(name='num_units 1', domain=Discrete([4, 8, 16]), display_name=None, description=None): 16,\n",
       " HParam(name='num_units 2', domain=Discrete([4, 8]), display_name=None, description=None): 4,\n",
       " HParam(name='l2 regularizer', domain=RealInterval(0.001, 0.01), display_name=None, description=None): 0.01,\n",
       " HParam(name='optimizer', domain=Discrete(['RMSprop', 'adam', 'sgd']), display_name=None, description=None): 'RMSprop'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.961028"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(rmse_list).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n",
    "#    hp.hparams_config(\n",
    "#    hparams=[HP_NUM_UNITS1,HP_NUM_UNITS2, HP_DROPOUT,HP_L2 ,HP_OPTIMIZER],\n",
    "#    metrics=[hp.Metric(METRIC_RMSE, display_name='RMSE')],\n",
    "#  )\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
