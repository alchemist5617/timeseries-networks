{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not import rpy package\n",
      "Could not import r-package RCIT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from netCDF4 import Dataset\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "import PCA_functions as pf\n",
    "import Extreme_functions as ef\n",
    "\n",
    "from tigramite import plotting as tp\n",
    "from tigramite.pcmci import PCMCI\n",
    "from tigramite.independence_tests import ParCorr, CMIknn\n",
    "import tigramite.data_processing as pp\n",
    "\n",
    "from Data import Data\n",
    "from datetime import datetime\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_obj(obj, name ):\n",
    "    with open(name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_obj(name ):\n",
    "    with open('obj/' + name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deseasonalize(data,freq=12):\n",
    "    \"\"\"\n",
    "    The shape of data should be (time, index) \n",
    "    \"\"\"\n",
    "    n  = data.shape[1]\n",
    "    N  = data.shape[0]\n",
    "    data_deseasonal = np.zeros(data.shape)\n",
    "    for i in range(n):\n",
    "        temp = np.copy(data[:,i])\n",
    "        r = np.zeros((N))\n",
    "        for j in range(freq):\n",
    "            Idx = np.arange(j,N,freq)\n",
    "            if temp[Idx].std() == 0:\n",
    "                r[Idx] = 0\n",
    "            else:\n",
    "                r[Idx] = (temp[Idx] - temp[Idx].mean())/temp[Idx].std()\n",
    "        data_deseasonal[:,i] = np.copy(r)\n",
    "    return(data_deseasonal)\n",
    "\n",
    "\n",
    "ET_gamma = np.load(\"ET_gamma.npy\")\n",
    "N = ET_gamma.shape[0]\n",
    "n_nodes = ET_gamma.shape[1]\n",
    "extremes_treshold = -1\n",
    "count = []\n",
    "for i in range(N):\n",
    "    count.append(np.count_nonzero(ET_gamma[i,:] <= extremes_treshold))\n",
    "\n",
    "level = 12\n",
    "temporal_limits = {\"time_min\":datetime(1977, 1, 1, 0, 0),\"time_max\":datetime(2015, 12, 1, 0, 0) }\n",
    "\n",
    "name = [\"../../nc/precip.mon.total.2.5x2.5.v2018.nc\",\"../../nc/pres.mon.mean.nc\",\"../../nc/air.mon.mean.nc\",\"../../nc/sst.mnmean.nc\"]\n",
    "code = [\"precip\", \"pres\", \"air\", \"sst\"]\n",
    "missing = [-9.96921e+36, -9.96921e+36, -9.96921e+36,-9.96921e+36]\n",
    "n_components = [87, 64, 82, 76]\n",
    "\n",
    "df_cluster = []\n",
    "for j in range(len(name)):\n",
    "    d = Data('{}'.format(name[j]),code[j],temporal_limits,missing_value=missing[j])\n",
    "\n",
    "    result = d.get_data()\n",
    "    lon_list = d.get_lon_list()\n",
    "    lat_list = d.get_lat_list()\n",
    "    lon = d.get_lon()\n",
    "    lat = d.get_lat()\n",
    "\n",
    "    result = deseasonalize(np.array(result))\n",
    "    weights = np.sqrt(np.abs(np.cos(np.array(lat_list)* math.pi/180)))\n",
    "    for i in range(len(weights)):\n",
    "        result[:,i] = weights[i] * result[:,i]\n",
    "               \n",
    "    data = pd.DataFrame(result)\n",
    "\n",
    "    scale = StandardScaler()\n",
    "    scaled_data = scale.fit_transform(data)\n",
    "\n",
    "    pca = PCA(n_components=n_components[j])\n",
    "    pca_model = pca.fit(scaled_data)\n",
    "\n",
    "    df_cluster.append(pca_model.transform(data))\n",
    "\n",
    "extremes_name  = [\"n_extremes\"]\n",
    "\n",
    "precip_name  = []\n",
    "for i in range(n_components[0]):\n",
    "    precip_name.append(\"PRECIP_%d\"%i)\n",
    "    \n",
    "pres_name  = []\n",
    "for i in range(n_components[1]):\n",
    "    pres_name.append(\"PRES_%d\"%i)\n",
    "    \n",
    "sat_name  = []\n",
    "for i in range(n_components[2]):\n",
    "    sat_name.append(\"SAT_%d\"%i)\n",
    "\n",
    "sst_name  = []\n",
    "for i in range(n_components[3]):\n",
    "    sst_name.append(\"SST_%d\"%i)\n",
    "#\n",
    "var_names = extremes_name + precip_name + pres_name + sat_name + sst_name\n",
    "#\n",
    "\n",
    "result_extremes = np.array(count)\n",
    "result_extremes = result_extremes.reshape((len(count),1))\n",
    "result_precip = np.matrix(df_cluster[0])\n",
    "result_pres = np.matrix(df_cluster[1])\n",
    "result_sat = np.matrix(df_cluster[2])\n",
    "result_sst = np.matrix(df_cluster[3])\n",
    "\n",
    "\n",
    "result = np.concatenate((result_extremes,result_precip, result_pres, result_sat, result_sst), axis=1)\n",
    "result = np.matrix(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pp.DataFrame(result,var_names=var_names)\n",
    "cond_ind_test = ParCorr()\n",
    "pcmci = PCMCI(dataframe=dataframe, cond_ind_test=cond_ind_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pcmci.run_pcmci(tau_max=2, pc_alpha=None)\n",
    "save_obj(results, \"results\")\n",
    "pcmci.print_significant_links(p_matrix=results['p_matrix'],\n",
    "                                     val_matrix=results['val_matrix'],\n",
    "                                     alpha_level=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_matrix = pcmci.get_corrected_pvalues(p_matrix=results['p_matrix'], fdr_method='fdr_bh')\n",
    "np.save(\"q_matrix.npy\",q_matrix)\n",
    "pcmci.print_significant_links(\n",
    "        p_matrix = results['p_matrix'], \n",
    "        q_matrix = q_matrix,\n",
    "        val_matrix = results['val_matrix'],\n",
    "        alpha_level = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
