{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not import rpy package\n",
      "Could not import r-package RCIT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mathsys2/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "from netCDF4 import Dataset\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "import PCA_functions as pf\n",
    "import Extreme_functions as ef\n",
    "\n",
    "from tigramite import plotting as tp\n",
    "from tigramite.pcmci import PCMCI\n",
    "from tigramite.independence_tests import ParCorr, CMIknn\n",
    "import tigramite.data_processing as pp\n",
    "\n",
    "from Data import Data\n",
    "from datetime import datetime\n",
    "\n",
    "import pickle\n",
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (20,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_obj(obj, name ):\n",
    "    with open(name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name ):\n",
    "    with open(name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def deseasonalize(data,freq=12):\n",
    "    \"\"\"\n",
    "    The shape of data should be (time, index) \n",
    "    \"\"\"\n",
    "    n  = data.shape[1]\n",
    "    N  = data.shape[0]\n",
    "    data_deseasonal = np.zeros(data.shape)\n",
    "    for i in range(n):\n",
    "        temp = np.copy(data[:,i])\n",
    "        r = np.zeros((N))\n",
    "        for j in range(freq):\n",
    "            Idx = np.arange(j,N,freq)\n",
    "            if temp[Idx].std() == 0:\n",
    "                r[Idx] = 0\n",
    "            else:\n",
    "                r[Idx] = (temp[Idx] - temp[Idx].mean())/temp[Idx].std()\n",
    "        data_deseasonal[:,i] = np.copy(r)\n",
    "    return(data_deseasonal)\n",
    "\n",
    "\n",
    "ET_gamma = np.load(\"ET_gamma.npy\")\n",
    "N = ET_gamma.shape[0]\n",
    "n_nodes = ET_gamma.shape[1]\n",
    "extremes_treshold = -1\n",
    "count = []\n",
    "for i in range(N):\n",
    "    count.append(np.count_nonzero(ET_gamma[i,:] <= extremes_treshold))\n",
    "\n",
    "level = 12\n",
    "temporal_limits = {\"time_min\":datetime(1977, 1, 1, 0, 0),\"time_max\":datetime(2015, 12, 1, 0, 0) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_MSE_finder1(count, result_sst, link,n_estimators=100, max_depth=5, tau=-1):\n",
    "    result =[]\n",
    "    link = link[link[:,1] <= tau]\n",
    "    refined_link = []\n",
    "    df = pd.DataFrame({\"drought\":count, \"drought1\":count})\n",
    "    df.drought1 = df.drought1.shift(abs(tau))\n",
    "    df = df.dropna()\n",
    "    index = int(df.shape[0]*0.7)\n",
    "    dim = df.shape[1]\n",
    "\n",
    "    x_train, x_test = df.iloc[:index,1:dim], df.iloc[index:,1:dim]\n",
    "    y_train, y_test = df.iloc[:index,0], df.iloc[index:,0]\n",
    "    model = RandomForestRegressor(max_depth=max_depth, random_state=0, n_estimators=n_estimators)\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    result.append(mean_squared_error(y_pred, y_test))\n",
    "\n",
    "\n",
    "    for z in range(len(link)):\n",
    "        df = pd.DataFrame({\"drought\":count, \"drought1\":count})\n",
    "        df.drought1 = df.drought1.shift(abs(tau))\n",
    "        for k in range(0,z+1):\n",
    "                if link[k,0] != 0:\n",
    "                    df[str(link[k,0]-1)] = result_sst[:,link[k,0]-1]\n",
    "                    df[str(link[k,0]-1)] = df[str(link[k,0]-1)].shift(abs(link[k,1]))\n",
    "                else:\n",
    "                    df[str(link[k,0])] = count\n",
    "                    df[str(link[k,0])] = df[str(link[k,0])].shift(abs(link[k,1]))\n",
    "        df = df.dropna()\n",
    "        index = int(df.shape[0]*0.7)\n",
    "        dim = df.shape[1]\n",
    "\n",
    "        x_train, x_test = df.iloc[:index,1:dim], df.iloc[index:,1:dim]\n",
    "        y_train, y_test = df.iloc[:index,0], df.iloc[index:,0]\n",
    "        model = RandomForestRegressor(max_depth=max_depth, random_state=0, n_estimators=n_estimators)\n",
    "        model.fit(x_train, y_train)\n",
    "        y_pred = model.predict(x_test)\n",
    "        mse = mean_squared_error(y_pred, y_test)\n",
    "        if mse < result[-1]:\n",
    "            result.append(mean_squared_error(y_pred, y_test))\n",
    "            refined_link.append(link[z])\n",
    "    return(result,np.array(refined_link))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_MSE_finder_xgboosting(count, result_sst, link,n_estimators=100, max_depth=5, tau=-1):\n",
    "    result =[]\n",
    "    link = link[link[:,1] <= tau]\n",
    "\n",
    "    df = pd.DataFrame({\"drought\":count, \"drought1\":count})\n",
    "    df.drought1 = df.drought1.shift(abs(tau))\n",
    "    df = df.dropna()\n",
    "    index = int(df.shape[0]*0.7)\n",
    "    dim = df.shape[1]\n",
    "\n",
    "    x_train, x_test = df.iloc[:index,1:dim], df.iloc[index:,1:dim] \n",
    "    y_train, y_test = df.iloc[:index,0], df.iloc[index:,0] \n",
    "    \n",
    "    #model = RandomForestRegressor(max_depth=max_depth, random_state=0, n_estimators=n_estimators)\n",
    "    #model = xgb.XGBRegressor(n_estimators=n_estimators,reg_lambda=1,gamma=0,max_depth=max_depth)\n",
    "    model = CatBoostRegressor(depth=2)\n",
    "    \n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    result.append(mean_squared_error(y_pred, y_test))\n",
    "\n",
    "\n",
    "    for z in range(len(link)):\n",
    "        df = pd.DataFrame({\"drought\":count, \"drought1\":count})\n",
    "        df.drought1 = df.drought1.shift(abs(tau))\n",
    "        for k in range(0,z+1):\n",
    "                if link[k,0] != 0:\n",
    "                    df[str(link[k,0]-1)] = result_sst[:,link[k,0]-1]\n",
    "                    df[str(link[k,0]-1)] = df[str(link[k,0]-1)].shift(abs(link[k,1]))\n",
    "                else:\n",
    "                    df[str(link[k,0])] = count\n",
    "                    df[str(link[k,0])] = df[str(link[k,0])].shift(abs(link[k,1]))\n",
    "        df = df.dropna()\n",
    "        index = int(df.shape[0]*0.7)\n",
    "        dim = df.shape[1]\n",
    "\n",
    "        x_train, x_test = df.iloc[:index,1:dim], df.iloc[index:,1:dim] \n",
    "        y_train, y_test = df.iloc[:index,0], df.iloc[index:,0] \n",
    "        #model = RandomForestRegressor(max_depth=max_depth, random_state=0, n_estimators=n_estimators)\n",
    "        #model = xgb.XGBRegressor(n_estimators=n_estimators,reg_lambda=1,gamma=0,max_depth=max_depth)\n",
    "        model = CatBoostRegressor(iterations=2,learning_rate=1,depth=16)\n",
    "        \n",
    "        model.fit(x_train, y_train)\n",
    "        y_pred = model.predict(x_test)\n",
    "        result.append(mean_squared_error(y_pred, y_test))\n",
    "    return(result,link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_MSE_finder(count, result_sst, link,n_estimators=100, max_depth=5, tau=-1):\n",
    "    result =[]\n",
    "    link = link[link[:,1] <= tau]\n",
    "\n",
    "    df = pd.DataFrame({\"drought\":count, \"drought1\":count})\n",
    "    df.drought1 = df.drought1.shift(abs(tau))\n",
    "    df = df.dropna()\n",
    "    index = int(df.shape[0]*0.7)\n",
    "    dim = df.shape[1]\n",
    "\n",
    "    x_train, x_test = df.iloc[:index,1:dim], df.iloc[index:,1:dim] \n",
    "    y_train, y_test = df.iloc[:index,0], df.iloc[index:,0] \n",
    "    model = RandomForestRegressor(max_depth=max_depth, random_state=0, n_estimators=n_estimators)\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    result.append(mean_squared_error(y_pred, y_test))\n",
    "\n",
    "\n",
    "    for z in range(len(link)):\n",
    "        df = pd.DataFrame({\"drought\":count, \"drought1\":count})\n",
    "        df.drought1 = df.drought1.shift(abs(tau))\n",
    "        for k in range(0,z+1):\n",
    "                if link[k,0] != 0:\n",
    "                    df[str(link[k,0]-1)] = result_sst[:,link[k,0]-1]\n",
    "                    df[str(link[k,0]-1)] = df[str(link[k,0]-1)].shift(abs(link[k,1]))\n",
    "                else:\n",
    "                    df[str(link[k,0])] = count\n",
    "                    df[str(link[k,0])] = df[str(link[k,0])].shift(abs(link[k,1]))\n",
    "        df = df.dropna()\n",
    "        index = int(df.shape[0]*0.7)\n",
    "        dim = df.shape[1]\n",
    "\n",
    "        x_train, x_test = df.iloc[:index,1:dim], df.iloc[index:,1:dim] \n",
    "        y_train, y_test = df.iloc[:index,0], df.iloc[index:,0] \n",
    "        model = RandomForestRegressor(max_depth=max_depth, random_state=0, n_estimators=n_estimators)\n",
    "        model.fit(x_train, y_train)\n",
    "        y_pred = model.predict(x_test)\n",
    "        result.append(mean_squared_error(y_pred, y_test))\n",
    "    return(result,link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_creator(name, code, missing, n_components, temporal_limits = temporal_limits):\n",
    "\n",
    "    d = Data('{}'.format(name),code,temporal_limits,missing_value=missing)\n",
    "\n",
    "    result = d.get_data()\n",
    "    lon_list = d.get_lon_list()\n",
    "    lat_list = d.get_lat_list()\n",
    "    lon = d.get_lon()\n",
    "    lat = d.get_lat()\n",
    "\n",
    "    result = deseasonalize(np.array(result))\n",
    "    weights = np.sqrt(np.abs(np.cos(np.array(lat_list)* math.pi/180)))\n",
    "    for i in range(len(weights)):\n",
    "        result[:,i] = weights[i] * result[:,i]\n",
    "\n",
    "    data = pd.DataFrame(result)\n",
    "    pca = PCA(n_components=n_components)\n",
    "    pca_model = pca.fit(data)\n",
    "\n",
    "    return(pca_model.transform(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = load_obj(\"results_st\")\n",
    "q_matrix = np.load(\"q_matrix_sst.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "pq_matrix = results['p_matrix']\n",
    "val_matrix = results['val_matrix']\n",
    "alpha_level = 0.05\n",
    "N = pq_matrix.shape[0]\n",
    "\n",
    "link_dict = dict()\n",
    "for j in range(N):\n",
    "    # Get the good links\n",
    "    good_links = np.argwhere(pq_matrix[:, j, 1:] <= alpha_level)\n",
    "    # Build a dictionary from these links to their values\n",
    "    links = {(i, -tau - 1): np.abs(val_matrix[i, j, abs(tau) + 1])\n",
    "             for i, tau in good_links}\n",
    "    # Sort by value\n",
    "    link_dict[j] = sorted(links, key=links.get, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_sst = result_creator(\"../../nc/sst.mnmean.nc\",\"sst\",-9.96921e+36,76)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = np.array(link_dict[0])\n",
    "if link[0,0] == 0:\n",
    "    link = link[1:,: ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators=100\n",
    "max_depth=100\n",
    "tau = -6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.random.shuffle(link[1:,:])\n",
    "link_list = []\n",
    "result, link = min_MSE_finder(count, result_sst, link,n_estimators, max_depth,tau)\n",
    "link_list.append(link)\n",
    "overall_min_MSE = []\n",
    "overall_min_MSE.append(min(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "diff = [x - result[i - 1] for i, x in enumerate(result)][1:]\n",
    "I = np.array(diff) < 0 \n",
    "while not all(I):\n",
    "    link_list.append(link)\n",
    "    link = link[I,:]\n",
    "    result, link = min_MSE_finder(count, result_sst, link,n_estimators, max_depth,tau)\n",
    "    overall_min_MSE.append(min(result))\n",
    "    diff = [x - result[i - 1] for i, x in enumerate(result)][1:]\n",
    "    I = np.array(diff) < 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = np.argmin(np.array(overall_min_MSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2, -12],\n",
       "       [ 72, -11],\n",
       "       [ 22,  -8],\n",
       "       [ 54,  -6],\n",
       "       [ 14,  -6],\n",
       "       [ 29, -10],\n",
       "       [  5,  -8],\n",
       "       [ 70,  -6],\n",
       "       [ 67,  -9],\n",
       "       [ 52,  -7],\n",
       "       [ 10,  -7],\n",
       "       [ 33,  -8],\n",
       "       [ 67,  -6]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link_list[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = link_list[i ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2', '72', '22', '54', '14', '29', '5', '70', '67', '52', '10', '33', '67']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(str,list(l[:,0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(468, 8)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_sst[:,l[:,0]-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def link_finder1(count, results_name, q_matrix_name, file_name, code, missing,\n",
    "                n_components, tau, n_estimators=100,max_depth=100):\n",
    "\n",
    "    results = load_obj(results_name)\n",
    "    q_matrix = np.load(q_matrix_name)\n",
    "\n",
    "    pq_matrix = results['p_matrix']\n",
    "    val_matrix = results['val_matrix']\n",
    "    alpha_level = 0.05\n",
    "    N = pq_matrix.shape[0]\n",
    "\n",
    "    link_dict = dict()\n",
    "    for j in range(N):\n",
    "        # Get the good links\n",
    "        good_links = np.argwhere(pq_matrix[:, j, 1:] <= alpha_level)\n",
    "        # Build a dictionary from these links to their values\n",
    "        links = {(i, -tau - 1): np.abs(val_matrix[i, j, abs(tau) + 1])\n",
    "                 for i, tau in good_links}\n",
    "        # Sort by value\n",
    "        link_dict[j] = sorted(links, key=links.get, reverse=True)\n",
    "\n",
    "    result_ = result_creator(file_name,code, missing, n_components)\n",
    "\n",
    "    link = np.array(link_dict[0])\n",
    "    if link[0,0] == 0:\n",
    "        link = link[1:,: ]\n",
    "\n",
    "    #np.random.shuffle(link[1:,:])\n",
    "\n",
    "    result, link = min_MSE_finder1(count, result_, link,n_estimators, max_depth,tau)\n",
    "\n",
    "    return(link, min(result))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def link_finder(count, results_name, q_matrix_name, file_name, code, missing,\n",
    "                n_components, tau, n_estimators=100,max_depth=100):\n",
    "    \n",
    "    results = load_obj(results_name)\n",
    "    q_matrix = np.load(q_matrix_name)\n",
    "\n",
    "    pq_matrix = results['p_matrix']\n",
    "    val_matrix = results['val_matrix']\n",
    "    alpha_level = 0.05\n",
    "    N = pq_matrix.shape[0]\n",
    "\n",
    "    link_dict = dict()\n",
    "    for j in range(N):\n",
    "        # Get the good links\n",
    "        good_links = np.argwhere(pq_matrix[:, j, 1:] <= alpha_level)\n",
    "        # Build a dictionary from these links to their values\n",
    "        links = {(i, -tau - 1): np.abs(val_matrix[i, j, abs(tau) + 1])\n",
    "                 for i, tau in good_links}\n",
    "        # Sort by value\n",
    "        link_dict[j] = sorted(links, key=links.get, reverse=True)\n",
    "\n",
    "    result_ = result_creator(file_name,code, missing, n_components)\n",
    "\n",
    "    link = np.array(link_dict[0])\n",
    "    if link[0,0] == 0:\n",
    "        link = link[1:,: ]\n",
    "\n",
    "    #np.random.shuffle(link[1:,:])\n",
    "    link_list = []\n",
    "    result, link = min_MSE_finder(count, result_, link,n_estimators, max_depth,tau)\n",
    "    link_list.append(link)\n",
    "    overall_min_MSE = []\n",
    "    overall_min_MSE.append(min(result))\n",
    "\n",
    "\n",
    "    diff = [x - result[i - 1] for i, x in enumerate(result)][1:]\n",
    "    I = np.array(diff) < 0 \n",
    "    while not all(I):\n",
    "        link_list.append(link)\n",
    "        link = link[I,:]\n",
    "        result, link = min_MSE_finder(count, result_, link,n_estimators, max_depth,tau)\n",
    "        overall_min_MSE.append(min(result))\n",
    "        diff = [x - result[i - 1] for i, x in enumerate(result)][1:]\n",
    "        I = np.array(diff) < 0 \n",
    "\n",
    "    i = np.argmin(np.array(overall_min_MSE))\n",
    "\n",
    "    return(link_list[i], overall_min_MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_link_sat, all_MSE_sat= link_finder(count,\"results_sat\",\"q_matrix_sat.npy\",\"../../nc/air.mon.mean.nc\",\"air\",-9.96921e+36,82,-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_link_sst, all_MSE_sst= link_finder(count,\"results_st\",\"q_matrix_sst.npy\",\"../../nc/sst.mnmean.nc\",\"sst\",-9.96921e+36,76,-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_list = []\n",
    "for i in range(2):\n",
    "    best_link_sst, all_MSE_sst= link_finder1(count,\"results_st\",\"q_matrix_sst.npy\",\"../../nc/sst.mnmean.nc\",\"sst\"\n",
    "                                            ,-9.96921e+36,76,-6)\n",
    "    result_list.append(best_link_sst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2, -12],\n",
       "       [ 22,  -8],\n",
       "       [ 52, -10],\n",
       "       [ 14,  -6],\n",
       "       [  5,  -8],\n",
       "       [ 39, -10],\n",
       "       [ 49,  -6],\n",
       "       [ 67, -12],\n",
       "       [ 34, -11],\n",
       "       [ 48, -10],\n",
       "       [ 33,  -8]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_link_sst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "885.5603021897809"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_MSE_sst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lt = result_list[0].T\n",
    "l = list(zip(lt[0],lt[1]))\n",
    "\n",
    "for i in range(1,len(result_list)):\n",
    "    lt = result_list[i].T\n",
    "    lt = list(zip(lt[0],lt[1]))\n",
    "    l = l + lt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dic = {}\n",
    "for item in set(l):\n",
    "    result_dic[item] = l.count(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, -12): 2,\n",
       " (0, -11): 2,\n",
       " (1, -10): 2,\n",
       " (2, -12): 2,\n",
       " (2, -11): 2,\n",
       " (5, -8): 2,\n",
       " (8, -12): 2,\n",
       " (10, -7): 2,\n",
       " (14, -6): 2,\n",
       " (17, -7): 2,\n",
       " (21, -7): 2,\n",
       " (22, -8): 2,\n",
       " (29, -10): 2,\n",
       " (33, -8): 2,\n",
       " (34, -11): 2,\n",
       " (38, -8): 2,\n",
       " (39, -10): 2,\n",
       " (43, -11): 2,\n",
       " (46, -11): 2,\n",
       " (48, -10): 2,\n",
       " (49, -6): 2,\n",
       " (52, -10): 2,\n",
       " (52, -7): 2,\n",
       " (54, -6): 2,\n",
       " (57, -6): 2,\n",
       " (67, -12): 2,\n",
       " (67, -9): 2,\n",
       " (67, -6): 2,\n",
       " (70, -6): 2,\n",
       " (71, -6): 2,\n",
       " (72, -11): 2,\n",
       " (72, -6): 2}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"./features/result_dic_{}.txtx\".format(abs(tau))\n",
    "save_obj(result_dic,file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"./features/result_dic_{}.txt\".format(abs(tau))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_name, 'w') as f:\n",
    "    for key, values in result_dic.items():\n",
    "        string = \"{},{}\\n\".format(key,values)\n",
    "        f.write(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33, -8),2\n",
      "(52, -7),1\n",
      "(22, -8),2\n",
      "(67, -9),1\n",
      "(54, -6),2\n",
      "(72, -11),2\n",
      "(2, -12),2\n",
      "(5, -8),2\n",
      "(10, -7),2\n",
      "(29, -10),2\n",
      "(48, -10),1\n",
      "(14, -6),2\n",
      "(38, -8),2\n",
      "(67, -6),2\n"
     ]
    }
   ],
   "source": [
    "for key, values in result_dic.items():\n",
    "    string = \"{},{}\".format(key,values)\n",
    "    print(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "lt = result_list[0].T\n",
    "l = list(zip(lt[0],lt[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,len(result_list)):\n",
    "    lt = result_list[i].T\n",
    "    lt = list(zip(lt[0],lt[1]))\n",
    "    l = l + lt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dic = {}\n",
    "for item in set(l):\n",
    "    result_dic[item] = l.count(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"./features/result_dic_{}\".format(abs(tau))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./features/result_dic_1'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_obj(result_dic,\"result_dic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = load_obj(\"result_dic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(2, -12): 10,\n",
       " (5, -8): 10,\n",
       " (10, -7): 5,\n",
       " (14, -6): 10,\n",
       " (22, -8): 10,\n",
       " (29, -10): 8,\n",
       " (33, -8): 10,\n",
       " (38, -8): 8,\n",
       " (48, -10): 1,\n",
       " (49, -6): 1,\n",
       " (52, -7): 7,\n",
       " (54, -6): 8,\n",
       " (67, -12): 1,\n",
       " (67, -9): 1,\n",
       " (67, -6): 5,\n",
       " (70, -6): 4,\n",
       " (71, -6): 3,\n",
       " (72, -11): 7,\n",
       " (72, -6): 5}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(result_list[0][:,:], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = result_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "lt = l.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    " l = list(zip(lt[0],lt[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, -12),\n",
       " (72, -11),\n",
       " (22, -8),\n",
       " (54, -6),\n",
       " (14, -6),\n",
       " (29, -10),\n",
       " (5, -8),\n",
       " (49, -6),\n",
       " (33, -8),\n",
       " (71, -6)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2, 72, 22, 54, 14, 29,  5, 49, 33, 71])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_list[0][:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau = 12\n",
    "file_name = './features/result_dic_{}.txt'.format(tau)\n",
    "with open(file_name, 'r') as f:\n",
    "    Lines = f.readlines()\n",
    "    \n",
    "result = {}\n",
    "for Line in Lines:\n",
    "    line = Line.strip().split(\")\")\n",
    "    key = (int(line[0].split(',')[0][1:]), int(line[0].split(',')[1].strip()))\n",
    "    value = int(line[1].strip(\",\"))\n",
    "    if value >= 475:\n",
    "        result[key] = value\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, -12): 500, (2, -12): 500, (8, -12): 500, (67, -12): 500}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_name = './features/result_dic_{}_new.txt'.format(tau)\n",
    "with open(file_name, 'r') as f:\n",
    "    Lines = f.readlines()\n",
    "\n",
    "result_new = {}\n",
    "for Line in Lines:\n",
    "    line = Line.strip().split(\")\")\n",
    "    key = (int(line[0].split(',')[0][1:]), int(line[0].split(',')[1].strip()))\n",
    "    value = int(line[1].strip(\",\"))\n",
    "    if value >= 475:\n",
    "        result_new[key] = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(2, -12): 500, (22, -8): 500, (33, -8): 500}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "line = Lines[0].strip().split(\")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52, -10)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(int(line[0].split(',')[0][1:]), int(line[0].split(',')[1].strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(line[1].strip(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "line = Lines[0].strip().split(\")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "475.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.95 * 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(52', ' -10']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line[0].split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau = 2\n",
    "file_name = './features/result_dic_{}_new.txt'.format(tau)\n",
    "with open(file_name, 'r') as f:\n",
    "    Lines = f.readlines()\n",
    "\n",
    "result = {}\n",
    "for Line in Lines:\n",
    "    line = Line.strip().split(\")\")\n",
    "    key = (int(line[0].split(',')[0][1:]), int(line[0].split(',')[1].strip()))\n",
    "    value = int(line[1].strip(\",\"))\n",
    "    if value >= 475:\n",
    "        result[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_link_pre, all_MSE_pre= link_finder(count,\"results_pre\",\"q_matrix_pre.npy\",\"../../nc/precip.mon.total.2.5x2.5.v2018.nc\"\n",
    "                                        ,\"precip\",-9.96921e+36,87,-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_link_pres, all_MSE_pres= link_finder(count,\"results_pres\",\"q_matrix_pres.npy\",\"../../nc/pres.mon.mean.nc\"\n",
    "                                        ,\"pres\",-9.96921e+36,64,-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "779.4454927392622"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(all_MSE_sst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
