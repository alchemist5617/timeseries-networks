{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import tensorflow_probability as tfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def univariate_data(dataset, start_index, end_index, history_size, target_size):\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    start_index = start_index + history_size\n",
    "    if end_index is None:\n",
    "        end_index = len(dataset) - target_size\n",
    "\n",
    "    for i in range(start_index, end_index):\n",
    "        indices = range(i-history_size, i)\n",
    "    # Reshape data from (history_size,) to (history_size, 1)\n",
    "        data.append(np.reshape(dataset[indices], (history_size, 1)))\n",
    "        labels.append(dataset[i+target_size])\n",
    "    return np.array(data), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequence(sequence, n_steps):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps\n",
    "        # check if we are beyond the sequence\n",
    "        if end_ix > len(sequence)-1:\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "\n",
    "def train_test_split_ts_2d_raw(X, h):\n",
    "    return(X[:-h],X[-h:])\n",
    "\n",
    "\n",
    "def train_test_split_ts(X, y, test_size=0.2):\n",
    "    r = X.shape[0]\n",
    "    split_index = int((1-test_size)*r)\n",
    "    return(X[:split_index,:,:],X[split_index:,:,:],y[:split_index],y[split_index:])\n",
    "\n",
    "def train_test_split_ts_index(X, y, split_index):\n",
    "    r = X.shape[0]\n",
    "    return(X[:split_index,:,:],X[split_index:,:,:],y[:split_index],y[split_index:])\n",
    "\n",
    "def train_test_split_ts_2d(X, y, test_size=0.2):\n",
    "    r = X.shape[0]\n",
    "    split_index = int((1-test_size)*r)\n",
    "    return(X[:split_index,:],X[split_index:,:],y[:split_index],y[split_index:])\n",
    "\n",
    "def train_test_split_ts_2d_index(X, y, split_index):\n",
    "    r = X.shape[0]\n",
    "    return(X[:split_index,:],X[split_index:,:],y[:split_index],y[split_index:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset, window_size = 1):\n",
    "    data_X, data_Y = [], []\n",
    "    for i in range(len(dataset) - window_size - 1):\n",
    "        a = dataset[i:(i + window_size)]\n",
    "        data_X.append(a)\n",
    "        data_Y.append(dataset[i + window_size])\n",
    "    return(np.array(data_X), np.array(data_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast(first_item, model, h, n_step):\n",
    "    x = first_item\n",
    "    result = []\n",
    "    #x = np.reshape(x,(1,20))\n",
    "    for i in range(h):\n",
    "        y = model.predict(np.reshape(x,(1,n_step)))\n",
    "        result.append(y)\n",
    "        x = np.append(x[1:],np.array(y))\n",
    "    return(np.array(result))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_steps, n_units, learning_rate, optimizer_name):\n",
    "    model = keras.Sequential()\n",
    "    if len(n_units) == 1:\n",
    "        model.add(layers.Dense(n_units[0], activation=tf.nn.relu, input_dim=n_steps))\n",
    "    else:  \n",
    "        model.add(layers.Dense(n_units[0], activation=tf.nn.relu, input_dim=n_steps))\n",
    "        for i in range(1,len(n_units)):\n",
    "            model.add(layers.Dense(n_units[i], activation=tf.nn.relu))\n",
    "    \n",
    "    model.add(layers.Dense(1))\n",
    "    \n",
    "    if optimizer_name == \"adam\":\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "    else:\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate)\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_hparam_tunning(x, n_steps, num_units, optimizer, learning_rate,\n",
    "                      training_window=15, forecast_window=1, freq=12,epochs=1):\n",
    "\n",
    "    fuzzify(x)\n",
    "    L = len(x)\n",
    "    errors = []\n",
    "    \n",
    "    for i in range(0, L - (training_window+forecast_window)*freq, freq):   \n",
    "\n",
    "        raw_seq = x[i:i+(training_window + forecast_window)*freq]\n",
    "\n",
    "        X, y_test = train_test_split_ts_2d_raw(raw_seq, forecast_window*freq) \n",
    "        X_train, y_train = split_sequence(X, n_steps)\n",
    "\n",
    "        #estimator = KerasRegressor(build_fn=baseline_ model(n_steps), epochs=100, batch_size=5, verbose=0)\n",
    "        model = build_model(n_steps, num_units, learning_rate, optimizer)\n",
    "\n",
    "\n",
    "        #EPOCHS = 100\n",
    "        model.fit(X_train, y_train, epochs=epochs, validation_split = 0.2, verbose=0)\n",
    "\n",
    "        y_hat = forecast(np.append(X_train[-1][1:],np.array(y_train[-1])), model, freq, n_steps)\n",
    "        y_hat = np.reshape(y_hat,len(y_test))\n",
    "        if np.any(np.isnan(y_hat)):\n",
    "            errors.append(np.nan)\n",
    "        else:\n",
    "            errors.append(math.sqrt(mean_squared_error(y_test,y_hat)))\n",
    "\n",
    "        #errors.append(math.sqrt(mean_squared_error(y_test,y_hat)))\n",
    "        \n",
    "    return(np.nanmean(errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uni_deseasonalize(ts,freq=12):\n",
    "    ts = np.array(ts)\n",
    "    avgs = np.zeros(freq)\n",
    "    stds = np.zeros(freq)\n",
    "    N = len(ts)\n",
    "    #averages = np.zeros((freq,n))\n",
    "    temp = ts\n",
    "    result = np.zeros((N))\n",
    "    for j in range(freq):\n",
    "        Idx = np.arange(j,N,freq)\n",
    "        avgs[j] = temp[Idx].mean()\n",
    "        stds[j] = temp[Idx].std()\n",
    "        result[Idx] = (temp[Idx] - temp[Idx].mean())#/temp[Idx].std()\n",
    "    return(result, avgs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('../data.npy')\n",
    "lat = np.load('../lat.npy')\n",
    "lon = np.load('../lon.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data[27,6,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 30\n",
    "# Set forecasting window length (in years)\n",
    "m = 3\n",
    "# Set annual sampling rate\n",
    "f = 12 \n",
    "L = len(x)\n",
    "errors = []\n",
    "j = 0\n",
    "\n",
    "\n",
    "start = 1946\n",
    "origin = 1960\n",
    "# Set annual sampling rate\n",
    "freq = 12\n",
    "h = m*f\n",
    "n_steps = 20\n",
    "\n",
    "index = (origin - start) * f\n",
    "\n",
    "#x.ts <- x[index:length(x)-1]\n",
    "\n",
    "train_start = index\n",
    "train_end = train_start+n*f-1\n",
    "\n",
    "test_start = train_end + 1\n",
    "test_end = test_start + m*f -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x[train_start:train_end]\n",
    "x_test = x[test_start:test_end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 30\n",
    "# Set forecasting window length (in years)\n",
    "m = 3\n",
    "# Set annual sampling rate\n",
    "f = 12 \n",
    "L = len(x)\n",
    "errors = []\n",
    "j = 0\n",
    "\n",
    "\n",
    "start = 1946\n",
    "origin = 1960\n",
    "# Set annual sampling rate\n",
    "freq = 12\n",
    "h = m*f\n",
    "n_steps = 20\n",
    "\n",
    "index = (origin - start) * f\n",
    "\n",
    "#x.ts <- x[index:length(x)-1]\n",
    "\n",
    "train_start = index\n",
    "train_end = train_start+n*f-1\n",
    "\n",
    "test_start = train_end + 1\n",
    "test_end = test_start + m*f -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define input sequence\n",
    "raw_seq = x[index:index+(n+m)*f]\n",
    "X, y_test = train_test_split_ts_2d_raw(raw_seq, h) \n",
    "X, avgs = uni_deseasonalize(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = split_sequence(X, n_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_units = [200,100,50,30,20,15,10]\n",
    "learning_rate = 0.001\n",
    "optimizer = 'sgd'\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(n_steps, n_units, learning_rate, optimizer)\n",
    "model.fit(X_train, y_train, epochs=epochs, validation_split = 0.2, verbose=0)\n",
    "y_hat = forecast(np.append(X_train[-1][1:],np.array(y_train[-1])), model, h, n_steps)\n",
    "y_hat = np.reshape(y_hat,len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgs = np.tile(avgs, int(len(y_hat)/f))\n",
    "#stds = np.tile(stds, int(len(y_hat)/f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.14633316286953"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.sqrt(mean_squared_error(y_test,y_hat + avgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if np.any(np.isnan(y_hat)):\n",
    "    errors.append(np.nan)\n",
    "else:\n",
    "    errors.append(math.sqrt(mean_squared_error(y_test,y_hat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('data.npy')\n",
    "lat = np.load('lat.npy')\n",
    "lon = np.load('lon.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data[22,8,2:dim(data)[3]]  #cluster==2\n",
    "#x<-data[28,7,3:dim(data)[3]]   #cluster==0\n",
    "x = data[21,7,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'epochs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-88-dd367a073459>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'epochs' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02, 0.02, 0.01, ..., 0.  , 0.  , 1.73],\n",
       "       [0.02, 0.01, 0.  , ..., 0.  , 1.73, 0.09],\n",
       "       [0.01, 0.  , 0.08, ..., 1.73, 0.09, 0.18],\n",
       "       ...,\n",
       "       [0.02, 0.01, 0.  , ..., 0.  , 0.19, 0.09],\n",
       "       [0.01, 0.  , 0.31, ..., 0.19, 0.09, 0.1 ],\n",
       "       [0.  , 0.31, 0.  , ..., 0.09, 0.1 , 0.  ]], dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=30\n",
    "# Set forecasting window length (in years)\n",
    "m=3\n",
    "# Set start year\n",
    "start = 1948\n",
    "origin = 1980\n",
    "# Set annual sampling rate\n",
    "f = 12\n",
    "h = m*f\n",
    "\n",
    "index = (origin - start) * f +1\n",
    "\n",
    "#x.ts <- x[index:length(x)-1]\n",
    "\n",
    "train_start = index\n",
    "train_end = train_start+n*f-1\n",
    "\n",
    "test_start = train_end + 1\n",
    "test_end = test_start + m*f -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "385"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "univariate_past_history = n*f\n",
    "univariate_future_target = 1\n",
    "\n",
    "x_train_uni, y_train_uni = univariate_data(x, train_start, test_start,\n",
    "                                           univariate_past_history,\n",
    "                                           univariate_future_target)\n",
    "x_val_uni, y_val_uni = univariate_data(x, test_start, test_end,\n",
    "                                       univariate_past_history,\n",
    "                                       univariate_future_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_time_steps(length):\n",
    "    return list(range(-length, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_plot(plot_data, delta, title):\n",
    "    labels = ['History', 'True Future', 'Model Prediction']\n",
    "    marker = ['.-', 'rx', 'go']\n",
    "    time_steps = create_time_steps(plot_data[0].shape[0])\n",
    "    if delta:\n",
    "        future = delta\n",
    "    else:\n",
    "        future = 0\n",
    "\n",
    "    plt.title(title)\n",
    "    for i, x in enumerate(plot_data):\n",
    "        if i:\n",
    "            plt.plot(future, plot_data[i], marker[i], markersize=10,\n",
    "                label=labels[i])\n",
    "        else:\n",
    "             plt.plot(time_steps, plot_data[i].flatten(), marker[i], label=labels[i])\n",
    "    plt.legend()\n",
    "    plt.xlim([time_steps[0], (future+5)*2])\n",
    "    plt.xlabel('Time-Step')\n",
    "    return plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline(history):\n",
    "    return np.mean(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-14ab6e7623b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mshow_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_train_uni\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_uni\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Sample Example'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "show_plot([x_train_uni[0], y_train_uni[0]], 0, 'Sample Example')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_uni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
