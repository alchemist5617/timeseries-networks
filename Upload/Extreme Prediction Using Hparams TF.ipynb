{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorboard.plugins.hparams import api as hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "HP_NUM_UNITS1 = hp.HParam('num_units 1', hp.Discrete([4,8,16])) \n",
    "HP_NUM_UNITS2 = hp.HParam('num_units 2', hp.Discrete([4,8]))\n",
    "#HP_DROPOUT = hp.HParam('dropout', hp.RealInterval(0.1, 0.3))\n",
    "HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam', 'sgd','RMSprop']))\n",
    "HP_L2 = hp.HParam('l2 regularizer', hp.RealInterval(.001,.01))\n",
    "METRIC_RMSE = 'RootMeanSquaredError'\n",
    "\n",
    "n = 26\n",
    "# Set forecasting window length (in years)\n",
    "m = 13\n",
    "# Set annual sampling rate\n",
    "f = 12 \n",
    "\n",
    "freq = 12\n",
    "h = m*f\n",
    "n_steps = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequence(sequence, n_steps):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps\n",
    "        # check if we are beyond the sequence\n",
    "        if end_ix > len(sequence)-1:\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "\n",
    "def train_test_split_ts_2d_raw(X, h):\n",
    "    return(X[:-h],X[-h:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_list = []\n",
    "for i in range(6):\n",
    "    file_name =\"../extreme_data/raw12_{}.csv\".format(i) \n",
    "    data = pd.read_csv(file_name)\n",
    "    \n",
    "    x = data.iloc[1:,1].values\n",
    "    oni = data.iloc[1:,2].values\n",
    "    \n",
    "\n",
    "    \n",
    "    #raw_seq = x[index:index+(n+m)*f]\n",
    "    X, y = split_sequence(x, n_steps)\n",
    "\n",
    "    #oni_seq = oni[index:index+(n+m)*f]\n",
    "    X_oni, _ = split_sequence(oni, n_steps)\n",
    "\n",
    "    #X = np.hstack((X_oni,X))\n",
    "    X = X_oni\n",
    "\n",
    "    #X_norm = (X - X.mean(0))/X.std(0)\n",
    "\n",
    "    x_train, x_test = train_test_split_ts_2d_raw(X, h)\n",
    "    y_train, y_test = train_test_split_ts_2d_raw(y, h)\n",
    "\n",
    "    def train_test_model(hparams):\n",
    "        model = tf.keras.Sequential([\n",
    "            tf.keras.layers.InputLayer(input_shape = x_train.shape[1]),\n",
    "            layers.Dense(hparams[HP_NUM_UNITS1], kernel_regularizer=tf.keras.regularizers.l2(0.001), activation=tf.nn.relu),\n",
    "            layers.Dropout(0.1),\n",
    "            layers.Dense(hparams[HP_NUM_UNITS2], kernel_regularizer=tf.keras.regularizers.l2(0.001), activation=tf.nn.relu),\n",
    "            layers.Dense(1)\n",
    "        ])\n",
    "\n",
    "        model.compile(optimizer=hparams[HP_OPTIMIZER],\n",
    "                    loss='mean_squared_error',\n",
    "                    metrics=['RootMeanSquaredError'])\n",
    "\n",
    "        model.fit(x_train, y_train, epochs=100,verbose=False) \n",
    "        _, rmse = model.evaluate(x_test, y_test, verbose=False)\n",
    "        return rmse\n",
    "\n",
    "    def run( hparams):\n",
    "        #with tf.summary.create_file_writer(run_dir).as_default():\n",
    "        hp.hparams(hparams)  # record the values used in this trial\n",
    "        rmse = train_test_model(hparams)\n",
    "        #    tf.summary.scalar(METRIC_RMSE, rmse, step=1)\n",
    "        return(rmse, hparams)\n",
    "\n",
    "    session_num = 0\n",
    "    min_rmse = float('inf')\n",
    "    best_hparams = {}\n",
    "    for num_units1 in HP_NUM_UNITS1.domain.values:\n",
    "        for num_units2 in HP_NUM_UNITS2.domain.values:\n",
    "            #for dropout_rate in (HP_DROPOUT.domain.min_value, HP_DROPOUT.domain.max_value):\n",
    "            for l2 in (HP_L2.domain.min_value, HP_L2.domain.max_value):\n",
    "                for optimizer in HP_OPTIMIZER.domain.values:\n",
    "                    hparams = {\n",
    "                        HP_NUM_UNITS1: num_units1,\n",
    "                        HP_NUM_UNITS2: num_units2,\n",
    "                        #HP_DROPOUT: dropout_rate,\n",
    "                        HP_L2: l2,\n",
    "                        HP_OPTIMIZER: optimizer\n",
    "                    }\n",
    "                    run_name = \"run-%d\" % session_num\n",
    "                    #print('--- Starting trial: %s' % run_name)\n",
    "                    #print({h.name: hparams[h] for h in hparams})\n",
    "                    rmse, current_hparams = run(hparams)\n",
    "                    if ~np.isnan(rmse) and rmse < min_rmse: \n",
    "                        best_hparams = current_hparams\n",
    "                        min_rmse = rmse\n",
    "                    session_num += 1\n",
    "\n",
    "    #params = list(best_hparams.values())\n",
    "    rmse_list.append(min_rmse)\n",
    "    #result_list.append(np.array(rmse_list).mean())\n",
    "\n",
    "np.save(\"ONIonly.npy\",np.array(rmse_list))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "onionly = rmse_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "spi = rmse_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = rmse_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "spioni = np.load(\"SPIWithONI_NoNormal.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawoni_noNormal = np.load(\"resultWithONI_NoNormal.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Raw without Enso</th>\n",
       "      <th>Raw with Enso</th>\n",
       "      <th>SPI without Enso</th>\n",
       "      <th>SPI with Enso</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.993443</td>\n",
       "      <td>4.990809</td>\n",
       "      <td>6.818307</td>\n",
       "      <td>6.532733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.106033</td>\n",
       "      <td>1.974325</td>\n",
       "      <td>3.605254</td>\n",
       "      <td>3.397066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.383949</td>\n",
       "      <td>1.518489</td>\n",
       "      <td>2.968959</td>\n",
       "      <td>3.099936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.077428</td>\n",
       "      <td>3.061981</td>\n",
       "      <td>4.690198</td>\n",
       "      <td>4.440694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.524236</td>\n",
       "      <td>1.571057</td>\n",
       "      <td>3.117165</td>\n",
       "      <td>3.128671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.612553</td>\n",
       "      <td>1.545339</td>\n",
       "      <td>2.509673</td>\n",
       "      <td>2.369509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Raw without Enso  Raw with Enso  SPI without Enso  SPI with Enso\n",
       "0          4.993443       4.990809          6.818307       6.532733\n",
       "1          2.106033       1.974325          3.605254       3.397066\n",
       "2          1.383949       1.518489          2.968959       3.099936\n",
       "3          3.077428       3.061981          4.690198       4.440694\n",
       "4          1.524236       1.571057          3.117165       3.128671\n",
       "5          1.612553       1.545339          2.509673       2.369509"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"Raw without Enso\":raw,\"Raw with Enso\":rawoni_noNormal, \n",
    "              \"SPI without Enso\":spi, \"SPI with Enso\":spioni\n",
    "               })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12 Months:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_corr = np.array([-0.314, 0.195, -0.018,-0.277, -0.029, 0.188])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_corr = np.array([-0.307, 0.191, -0.013,-0.276, -0.033, 0.192])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPI_corr = np.array([-0.273, 0.263, 0.149, -0.189, -0.093, 0.326])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Raw data</th>\n",
       "      <th>Anomaly data</th>\n",
       "      <th>SPI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-0.314</td>\n",
       "      <td>-0.307</td>\n",
       "      <td>-0.273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>0.149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.277</td>\n",
       "      <td>-0.276</td>\n",
       "      <td>-0.189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>-0.093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Raw data  Anomaly data    SPI\n",
       "0    -0.314        -0.307 -0.273\n",
       "1     0.195         0.191  0.263\n",
       "2    -0.018        -0.013  0.149\n",
       "3    -0.277        -0.276 -0.189\n",
       "4    -0.029        -0.033 -0.093\n",
       "5     0.188         0.192  0.326"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"Raw data\":raw_corr,\"Anomaly data\":anomaly_corr, \n",
    "              \"SPI\":SPI_corr})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_corr = np.array([-0.197, 0.021, -0.022,-0.145, -0.045, 0.129])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_corr = np.array([-0.06, 0.064, 0.018,-0.070, -0.009, 0.084])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPI_corr = np.array([-0.153, 0.034, -0.018, -0.112, -0.081, 0.094])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Raw data</th>\n",
       "      <th>Anomaly data</th>\n",
       "      <th>SPI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-0.197</td>\n",
       "      <td>-0.060</td>\n",
       "      <td>-0.153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>0.018</td>\n",
       "      <td>-0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.145</td>\n",
       "      <td>-0.070</td>\n",
       "      <td>-0.112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>-0.081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Raw data  Anomaly data    SPI\n",
       "0    -0.197        -0.060 -0.153\n",
       "1     0.021         0.064  0.034\n",
       "2    -0.022         0.018 -0.018\n",
       "3    -0.145        -0.070 -0.112\n",
       "4    -0.045        -0.009 -0.081\n",
       "5     0.129         0.084  0.094"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"Raw data\":raw_corr,\"Anomaly data\":anomaly_corr, \n",
    "              \"SPI\":SPI_corr})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Months:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_corr = np.array([-0.082, 0.005, -0.007, -0.101, -0.026, 0.092])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_corr = np.array([-0.022, 0.032, 0.013, -0.036, 0.005, 0.079])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPI_corr = np.array([-0.079, 0.002, -0.035, -0.091, -0.017, 0.034])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Raw data</th>\n",
       "      <th>Anomaly data</th>\n",
       "      <th>SPI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-0.197</td>\n",
       "      <td>-0.060</td>\n",
       "      <td>-0.079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>0.018</td>\n",
       "      <td>-0.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.145</td>\n",
       "      <td>-0.070</td>\n",
       "      <td>-0.091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>-0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Raw data  Anomaly data    SPI\n",
       "0    -0.197        -0.060 -0.079\n",
       "1     0.021         0.064  0.002\n",
       "2    -0.022         0.018 -0.035\n",
       "3    -0.145        -0.070 -0.091\n",
       "4    -0.045        -0.009 -0.017\n",
       "5     0.129         0.084  0.034"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"Raw data\":raw_corr,\"Anomaly data\":anomaly_corr, \n",
    "              \"SPI\":SPI_corr})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'L' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-dadd202ed627>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mrmse_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mraw_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'L' is not defined"
     ]
    }
   ],
   "source": [
    "result_list = []\n",
    "for i in range(6):\n",
    "    file_name =\"../extreme_data/raw12_{}.csv\".format(i) \n",
    "    data = pd.read_csv(file_name)\n",
    "    \n",
    "    x = data.iloc[1:,1].values\n",
    "    #oni = data.iloc[1:,2].values\n",
    "    \n",
    "    rmse_list = []\n",
    "    for index in range(0,int((L - (n+m)*f)/12)):\n",
    "        raw_seq = x[index:index+(n+m)*f]\n",
    "        X, y = split_sequence(raw_seq, n_steps)\n",
    "\n",
    "        #oni_seq = oni[index:index+(n+m)*f]\n",
    "        #X_oni, _ = split_sequence(oni_seq, n_steps)\n",
    "\n",
    "        #X = np.hstack((X_oni,X))\n",
    "\n",
    "        #X_norm = (X - X.mean(0))/X.std(0)\n",
    "\n",
    "        x_train, x_test = train_test_split_ts_2d_raw(X, h)\n",
    "        y_train, y_test = train_test_split_ts_2d_raw(y, h)\n",
    "\n",
    "        def train_test_model(hparams):\n",
    "            model = tf.keras.Sequential([\n",
    "                tf.keras.layers.InputLayer(input_shape = x_train.shape[1]),\n",
    "                layers.Dense(hparams[HP_NUM_UNITS1], kernel_regularizer=tf.keras.regularizers.l2(0.001), activation=tf.nn.relu),\n",
    "                layers.Dropout(0.1),\n",
    "                layers.Dense(hparams[HP_NUM_UNITS2], kernel_regularizer=tf.keras.regularizers.l2(0.001), activation=tf.nn.relu),\n",
    "                layers.Dense(1)\n",
    "            ])\n",
    "\n",
    "            model.compile(optimizer=hparams[HP_OPTIMIZER],\n",
    "                        loss='mean_squared_error',\n",
    "                        metrics=['RootMeanSquaredError'])\n",
    "\n",
    "            model.fit(x_train, y_train, epochs=100,verbose=False) \n",
    "            _, rmse = model.evaluate(x_test, y_test, verbose=False)\n",
    "            return rmse\n",
    "\n",
    "        def run( hparams):\n",
    "            #with tf.summary.create_file_writer(run_dir).as_default():\n",
    "            hp.hparams(hparams)  # record the values used in this trial\n",
    "            rmse = train_test_model(hparams)\n",
    "            #    tf.summary.scalar(METRIC_RMSE, rmse, step=1)\n",
    "            return(rmse, hparams)\n",
    "\n",
    "        session_num = 0\n",
    "        min_rmse = float('inf')\n",
    "        best_hparams = {}\n",
    "        for num_units1 in HP_NUM_UNITS1.domain.values:\n",
    "            for num_units2 in HP_NUM_UNITS2.domain.values:\n",
    "                #for dropout_rate in (HP_DROPOUT.domain.min_value, HP_DROPOUT.domain.max_value):\n",
    "                for l2 in (HP_L2.domain.min_value, HP_L2.domain.max_value):\n",
    "                    for optimizer in HP_OPTIMIZER.domain.values:\n",
    "                        hparams = {\n",
    "                            HP_NUM_UNITS1: num_units1,\n",
    "                            HP_NUM_UNITS2: num_units2,\n",
    "                            #HP_DROPOUT: dropout_rate,\n",
    "                            HP_L2: l2,\n",
    "                            HP_OPTIMIZER: optimizer\n",
    "                        }\n",
    "                        run_name = \"run-%d\" % session_num\n",
    "                        #print('--- Starting trial: %s' % run_name)\n",
    "                        #print({h.name: hparams[h] for h in hparams})\n",
    "                        rmse, current_hparams = run(hparams)\n",
    "                        if ~np.isnan(rmse) and rmse < min_rmse: \n",
    "                            best_hparams = current_hparams\n",
    "                            min_rmse = rmse\n",
    "                        session_num += 1\n",
    "\n",
    "        params = list(best_hparams.values())\n",
    "        rmse_list.append(min_rmse)\n",
    "    result_list.append(np.array(rmse_list).mean())\n",
    "\n",
    "np.save(\"resultWithoutONI.npy\",np.array(result_list))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.iloc[1:,1].values\n",
    "oni = data.iloc[1:,2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_list = []\n",
    "for index in range(0,int((L - (n+m)*f)/12)):\n",
    "    raw_seq = x[index:index+(n+m)*f]\n",
    "    X, y = split_sequence(raw_seq, n_steps)\n",
    "\n",
    "    #oni_seq = oni[index:index+(n+m)*f]\n",
    "    #X_oni, _ = split_sequence(oni_seq, n_steps)\n",
    "\n",
    "    #X = np.hstack((X_oni,X))\n",
    "\n",
    "    #X_norm = (X - X.mean(0))/X.std(0)\n",
    "\n",
    "    x_train, x_test = train_test_split_ts_2d_raw(X, h)\n",
    "    y_train, y_test = train_test_split_ts_2d_raw(y, h)\n",
    "\n",
    "    def train_test_model(hparams):\n",
    "        model = tf.keras.Sequential([\n",
    "            tf.keras.layers.InputLayer(input_shape = x_train.shape[1]),\n",
    "            layers.Dense(hparams[HP_NUM_UNITS1], kernel_regularizer=tf.keras.regularizers.l2(0.001), activation=tf.nn.relu),\n",
    "            layers.Dropout(0.1),\n",
    "            layers.Dense(hparams[HP_NUM_UNITS2], kernel_regularizer=tf.keras.regularizers.l2(0.001), activation=tf.nn.relu),\n",
    "            layers.Dense(1)\n",
    "        ])\n",
    "\n",
    "        model.compile(optimizer=hparams[HP_OPTIMIZER],\n",
    "                    loss='mean_squared_error',\n",
    "                    metrics=['RootMeanSquaredError'])\n",
    "\n",
    "        model.fit(x_train, y_train, epochs=100,verbose=False) \n",
    "        _, rmse = model.evaluate(x_test, y_test, verbose=False)\n",
    "        return rmse\n",
    "\n",
    "    def run( hparams):\n",
    "        #with tf.summary.create_file_writer(run_dir).as_default():\n",
    "        hp.hparams(hparams)  # record the values used in this trial\n",
    "        rmse = train_test_model(hparams)\n",
    "        #    tf.summary.scalar(METRIC_RMSE, rmse, step=1)\n",
    "        return(rmse, hparams)\n",
    "\n",
    "    session_num = 0\n",
    "    min_rmse = float('inf')\n",
    "    best_hparams = {}\n",
    "    for num_units1 in HP_NUM_UNITS1.domain.values:\n",
    "        for num_units2 in HP_NUM_UNITS2.domain.values:\n",
    "            #for dropout_rate in (HP_DROPOUT.domain.min_value, HP_DROPOUT.domain.max_value):\n",
    "            for l2 in (HP_L2.domain.min_value, HP_L2.domain.max_value):\n",
    "                for optimizer in HP_OPTIMIZER.domain.values:\n",
    "                    hparams = {\n",
    "                        HP_NUM_UNITS1: num_units1,\n",
    "                        HP_NUM_UNITS2: num_units2,\n",
    "                        #HP_DROPOUT: dropout_rate,\n",
    "                        HP_L2: l2,\n",
    "                        HP_OPTIMIZER: optimizer\n",
    "                    }\n",
    "                    run_name = \"run-%d\" % session_num\n",
    "                    #print('--- Starting trial: %s' % run_name)\n",
    "                    #print({h.name: hparams[h] for h in hparams})\n",
    "                    rmse, current_hparams = run(hparams)\n",
    "                    if ~np.isnan(rmse) and rmse < min_rmse: \n",
    "                        best_hparams = current_hparams\n",
    "                        min_rmse = rmse\n",
    "                    session_num += 1\n",
    "\n",
    "    params = list(best_hparams.values())\n",
    "    rmse_list.append(min_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{HParam(name='num_units 1', domain=Discrete([4, 8, 16]), display_name=None, description=None): 16,\n",
       " HParam(name='num_units 2', domain=Discrete([4, 8]), display_name=None, description=None): 4,\n",
       " HParam(name='l2 regularizer', domain=RealInterval(0.001, 0.01), display_name=None, description=None): 0.01,\n",
       " HParam(name='optimizer', domain=Discrete(['RMSprop', 'adam', 'sgd']), display_name=None, description=None): 'RMSprop'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.961028"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(rmse_list).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n",
    "#    hp.hparams_config(\n",
    "#    hparams=[HP_NUM_UNITS1,HP_NUM_UNITS2, HP_DROPOUT,HP_L2 ,HP_OPTIMIZER],\n",
    "#    metrics=[hp.Metric(METRIC_RMSE, display_name='RMSE')],\n",
    "#  )\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
