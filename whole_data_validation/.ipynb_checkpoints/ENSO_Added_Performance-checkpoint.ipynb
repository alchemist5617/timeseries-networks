{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from scipy import eye, asarray, dot, sum, diag\n",
    "from scipy.linalg import svd\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "import matplotlib as mpl\n",
    "from matplotlib import cm\n",
    "from colorspacious import cspace_converter\n",
    "from collections import OrderedDict\n",
    "from netCDF4 import Dataset\n",
    "from numpy import linspace\n",
    "from numpy import meshgrid\n",
    "\n",
    "\n",
    "import PCA_functions as pf\n",
    "import Extreme_functions as ef\n",
    "\n",
    "from tigramite import plotting as tp\n",
    "from tigramite.pcmci import PCMCI\n",
    "from tigramite.independence_tests import ParCorr, CMIknn\n",
    "import tigramite.data_processing as pp\n",
    "\n",
    "from Data import Data\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import itertools\n",
    "from collections import Counter\n",
    "import pickle\n",
    "\n",
    "from numpy import linalg as LA\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "from scipy.special import inv_boxcox\n",
    "from scipy import stats\n",
    "\n",
    "from matplotlib import animation\n",
    "\n",
    "import scipy.stats as st\n",
    "\n",
    "import reverse_geocoder as rg\n",
    "\n",
    "from pandas_datareader import wb\n",
    "import scipy.stats as st\n",
    "\n",
    "import Rung as rung\n",
    "\n",
    "from pandas_datareader import wb\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import feature_finder_keiko as ff\n",
    "import feature_finder_f as ff1\n",
    "\n",
    "from scipy import signal\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (20,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeseries(file_name, start_year = 1950, end_year=2015, base_year = 1950):\n",
    "    start_index = (start_year - base_year) * 12   \n",
    "    end_index = start_index + (end_year - (start_year - 1))*12\n",
    "    data = np.load(file_name)\n",
    "    return(data[start_index:end_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "nino = np.load('nino.npy')\n",
    "oni = np.load('oni.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "nino = timeseries('nino.npy', start_year = 1950, end_year=1951)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 1\n",
    "train_start = np.arange(1950,1977,step)\n",
    "#train_end = np.arange(1955,2006,step)\n",
    "validation_end = np.arange(1984,2011,step)\n",
    "test_start = np.arange(1985,2012,step)\n",
    "test_end = np.arange(1989,2016,step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "f =12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for tau in np.arange(1,13):\n",
    "    result = []\n",
    "    for ijz in range(26,len(train_start)):\n",
    "        temporal_limits = {\"time_min\":datetime(train_start[ijz], 1, 1, 0, 0),\"time_max\":datetime(validation_end[ijz], 12, 1, 0, 0)}\n",
    "        count, _ = ff.drought_timeseries(\"../npy_files/ET_gamma_18912015.npy\",train_start[ijz],validation_end[ijz])\n",
    "        enso = timeseries('nino.npy',train_start[ijz],validation_end[ijz])\n",
    "\n",
    "        start_lag = tau\n",
    "        end_lag = tau + 11\n",
    "\n",
    "        df_count = pd.DataFrame({\"drought\": count})\n",
    "        lags = np.arange(start_lag,end_lag + 1)\n",
    "        df_count = df_count.assign(**{\n",
    "        '{} (t-{})'.format(col, t): df_count[col].shift(t)\n",
    "        for t in lags\n",
    "        for col in df_count\n",
    "        })\n",
    "\n",
    "        df_enso = pd.DataFrame({\"enso\": enso})\n",
    "        lags = np.arange(start_lag,end_lag + 1)\n",
    "        df_enso = df_enso.assign(**{\n",
    "        '{} (t-{})'.format(col, t): df_enso[col].shift(t)\n",
    "        for t in lags\n",
    "        for col in df_enso\n",
    "        })\n",
    "\n",
    "        df_enso = df_enso.drop(['enso'],1)\n",
    "\n",
    "        df = pd.concat([df_count, df_enso],axis=1)\n",
    "        df = df.dropna()\n",
    "\n",
    "        x_train = df.iloc[:,1:]\n",
    "        y_train = df.iloc[:,0]\n",
    "        model = RandomForestRegressor(max_depth=5, random_state=0, n_estimators=100)\n",
    "        model.fit(x_train, y_train)\n",
    "\n",
    "        temporal_limits = {\"time_min\":datetime(test_start[ijz], 1, 1, 0, 0),\"time_max\":datetime(test_end[ijz], 12, 1, 0, 0)}\n",
    "        count, _ = ff.drought_timeseries(\"../npy_files/ET_gamma_18912015.npy\",test_start[ijz],test_end[ijz])\n",
    "        enso = timeseries('nino.npy',test_start[ijz],test_end[ijz])\n",
    "\n",
    "        df_count = pd.DataFrame({\"drought\": count})\n",
    "        lags = np.arange(start_lag,end_lag + 1)\n",
    "        df_count = df_count.assign(**{\n",
    "        '{} (t-{})'.format(col, t): df_count[col].shift(t)\n",
    "        for t in lags\n",
    "        for col in df_count\n",
    "        })\n",
    "\n",
    "        df_enso = pd.DataFrame({\"enso\": enso})\n",
    "        lags = np.arange(start_lag,end_lag + 1)\n",
    "        df_enso = df_enso.assign(**{\n",
    "        '{} (t-{})'.format(col, t): df_enso[col].shift(t)\n",
    "        for t in lags\n",
    "        for col in df_enso\n",
    "        })\n",
    "\n",
    "        df_enso = df_enso.drop(['enso'],1)\n",
    "\n",
    "        df = pd.concat([df_count, df_enso],axis=1)\n",
    "        df = df.dropna()\n",
    "\n",
    "        x_test = df.iloc[:,1:]\n",
    "        y_test = df.iloc[:,0]\n",
    "\n",
    "        y_pred = model.predict(x_test)\n",
    "\n",
    "        result.append(mean_squared_error(y_pred, y_test))\n",
    "    np.save(\"./enso/model_{}_{}_{}_{}_{}.npy\".format(f,step,test_start[0],test_end[-1],tau),result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[79.9684988731764,\n",
       " 237.95274624448973,\n",
       " 563.3475660809452,\n",
       " 947.2434550270092,\n",
       " 1404.1073700699762,\n",
       " 1989.2321164841999,\n",
       " 2443.3799679479166,\n",
       " 2512.1706685360136,\n",
       " 2862.78825365628,\n",
       " 2908.93359627239,\n",
       " 3064.1886594762336,\n",
       " 3066.0141542219626]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
